{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's new in MojoðŸ”¥ SDK v0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "from algorithm import vectorize\n",
    "\n",
    "\n",
    "struct SquareMatrix[dtype: DType = DType.float32, dim: Int = 4]():\n",
    "    var mat: Tensor[dtype]\n",
    "\n",
    "    fn __init__(inout self, val: SIMD[dtype, 1] = 5):\n",
    "        self.mat = Tensor[dtype](self.dim, self.dim)\n",
    "        alias simd_width = simdwidthof[dtype]()\n",
    "\n",
    "        @parameter\n",
    "        fn fill_val[simd_width: Int](idx: Int) -> None:\n",
    "            self.mat.simd_store(idx, self.mat.simd_load[simd_width](idx).splat(val))\n",
    "\n",
    "        vectorize[fill_val, simd_width](self.mat.num_elements())\n",
    "\n",
    "    fn __getitem__(self, x: Int, y: Int) -> SIMD[dtype, 1]:\n",
    "        return self.mat[x, y]\n",
    "\n",
    "    fn print(self):\n",
    "        print(self.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0]], dtype=float32, shape=4x4)\n"
     ]
    }
   ],
   "source": [
    "SquareMatrix().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[12.0, 12.0, 12.0, 12.0],\n",
      "[12.0, 12.0, 12.0, 12.0],\n",
      "[12.0, 12.0, 12.0, 12.0],\n",
      "[12.0, 12.0, 12.0, 12.0]], dtype=float32, shape=4x4)\n"
     ]
    }
   ],
   "source": [
    "SquareMatrix(val=12).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[10.0, 10.0, 10.0, 10.0],\n",
      "[10.0, 10.0, 10.0, 10.0],\n",
      "[10.0, 10.0, 10.0, 10.0],\n",
      "[10.0, 10.0, 10.0, 10.0]], dtype=float64, shape=4x4)\n"
     ]
    }
   ],
   "source": [
    "SquareMatrix[DType.float64](10).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[1.0, 1.0, 1.0],\n",
      "[1.0, 1.0, 1.0],\n",
      "[1.0, 1.0, 1.0]], dtype=float64, shape=3x3)\n"
     ]
    }
   ],
   "source": [
    "SquareMatrix[DType.float64,dim=3](1).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[1.5, 1.5, 1.5],\n",
      "[1.5, 1.5, 1.5],\n",
      "[1.5, 1.5, 1.5]], dtype=float64, shape=3x3)\n"
     ]
    }
   ],
   "source": [
    "SquareMatrix[dtype=DType.float64,dim=3](val=1.5).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword argument in `__getitem__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0]], dtype=float32, shape=4x4)\n",
      "\n",
      "Keyword argument in __getitem__()\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "var sm = SquareMatrix()\n",
    "sm.print()\n",
    "\n",
    "print()\n",
    "print(\"Keyword argument in __getitem__()\")\n",
    "print(sm[x=0, y=3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic parameterization of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameters are automatically added as input parameters on the function\n",
    "* Function argument input parameters can now be referenced within the signature of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[500.0, 500.0, 500.0, 500.0],\n",
      "[500.0, 500.0, 500.0, 500.0],\n",
      "[500.0, 500.0, 500.0, 500.0],\n",
      "[500.0, 500.0, 500.0, 500.0]], dtype=float32, shape=4x4)\n"
     ]
    }
   ],
   "source": [
    "from math import mul\n",
    "\n",
    "\n",
    "fn multiply(sm: SquareMatrix, val: SIMD[sm.dtype, 1]) -> Tensor[sm.dtype]:\n",
    "    alias simd_width: Int = simdwidthof[sm.dtype]()\n",
    "    var result_tensor = Tensor[sm.dtype](sm.mat.shape())\n",
    "\n",
    "    @parameter\n",
    "    fn vectorize_multiply[simd_width: Int](idx: Int) -> None:\n",
    "        result_tensor.simd_store[simd_width](\n",
    "            idx, mul[sm.dtype, simd_width](sm.mat.simd_load[simd_width](idx), val)\n",
    "        )\n",
    "\n",
    "    vectorize[vectorize_multiply, simd_width](sm.mat.num_elements())\n",
    "    return result_tensor\n",
    "\n",
    "\n",
    "fn main():\n",
    "    var sm = SquareMatrix(5)\n",
    "    var res = multiply(sm, 100.0)\n",
    "    print(res)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save Tensors + String enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "from algorithm import vectorize\n",
    "from time import now\n",
    "from memory import memcpy\n",
    "\n",
    "\n",
    "struct SquareMatrix[dtype: DType = DType.float32, dim: Int = 4]():\n",
    "    var mat: Tensor[dtype]\n",
    "\n",
    "    fn __init__(inout self, val: SIMD[dtype, 1] = 5):\n",
    "        self.mat = Tensor[dtype](self.dim, self.dim)\n",
    "        alias simd_width = simdwidthof[dtype]()\n",
    "\n",
    "        @parameter\n",
    "        fn fill_val[simd_width: Int](idx: Int) -> None:\n",
    "            self.mat.simd_store(idx, self.mat.simd_load[simd_width](idx).splat(val))\n",
    "\n",
    "        vectorize[fill_val, simd_width](self.mat.num_elements())\n",
    "\n",
    "    fn print(self):\n",
    "        print(self.mat)\n",
    "\n",
    "    fn prepare_filename(self, fname: String) -> String:\n",
    "        var fpath = fname\n",
    "        if fpath.count(\".\") < 2:\n",
    "            fpath += \".data\"\n",
    "        fpath = fpath.replace(\".\", \"_\" + self.mat.spec().__str__() + \".\")\n",
    "        if fpath.find(\"/\"):\n",
    "            fpath = \"./\" + fpath\n",
    "        return fpath\n",
    "\n",
    "    fn save(self, fname: String = \"saved_matrix\") raises -> String:\n",
    "        var fpath = self.prepare_filename(fname)\n",
    "        self.mat.tofile(fpath)\n",
    "        print(\"File saved:\", fpath)\n",
    "        return fpath\n",
    "\n",
    "    @staticmethod\n",
    "    fn load[dtype: DType, dim: Int](fpath: String) raises -> Tensor[dtype]:\n",
    "        var load_mat = Tensor[dtype].fromfile(fpath)\n",
    "        var new_tensor = Tensor[dtype](dim, dim)\n",
    "        memcpy(new_tensor.data(), load_mat.data(), load_mat.num_elements())\n",
    "        _ = load_mat\n",
    "        return new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0]], dtype=float32, shape=4x4)\n",
      "File saved: ./saved_matrix_4x4xfloat32.data\n"
     ]
    }
   ],
   "source": [
    "var m = SquareMatrix()\n",
    "m.print()\n",
    "var fpath = m.save(\"saved_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tensor from file: ./saved_matrix_4x4xfloat32.data\n",
      "\n",
      "Tensor([[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0],\n",
      "[5.0, 5.0, 5.0, 5.0]], dtype=float32, shape=4x4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Tensor from file:\", fpath)\n",
    "print()\n",
    "var load_mat = SquareMatrix.load[DType.float32, 4](fpath)\n",
    "print(load_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark row-wise `mean()` of a matrix by vectorizing across columns and parallelizing across rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[0.085032448172569275, 0.89161127805709839, 0.18968977034091949, ..., 0.74351245164871216, 0.5603899359703064, 0.8095666766166687],\n",
      "[0.51171255111694336, 0.99508452415466309, 0.96661138534545898, ..., 0.65299874544143677, 0.96153312921524048, 0.85798734426498413],\n",
      "[0.29402613639831543, 0.41464456915855408, 0.51489287614822388, ..., 0.544272780418396, 0.093629911541938782, 0.43225952982902527],\n",
      "[0.84492743015289307, 0.77284646034240723, 0.19185894727706909, ..., 0.18134318292140961, 0.57914149761199951, 0.31413143873214722],\n",
      "[0.41198459267616272, 0.9923054575920105, 0.16392241418361664, ..., 0.076218202710151672, 0.17452387511730194, 0.037299912422895432]], dtype=float32, shape=5x7)\n"
     ]
    }
   ],
   "source": [
    "from random import rand\n",
    "var tx = rand[DType.float32](5,7)\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Benchmark Report (s)\n",
      "---------------------\n",
      "Mean: 0.3632043333333333\n",
      "Total: 2.1792259999999999\n",
      "Iters: 6\n",
      "Warmup Mean: 0.37432949999999998\n",
      "Warmup Total: 0.74865899999999996\n",
      "Warmup Iters: 2\n",
      "Fastest Mean: 1.7976931348623157e+308\n",
      "Slowest Mean: 0.3632043333333333\n",
      "\n",
      "---------------------\n",
      "Benchmark Report (s)\n",
      "---------------------\n",
      "Mean: 0.0065975499999999998\n",
      "Total: 1.31951\n",
      "Iters: 200\n",
      "Warmup Mean: 0.0081960000000000002\n",
      "Warmup Total: 0.016392\n",
      "Warmup Iters: 2\n",
      "Fastest Mean: 0.0065975499999999998\n",
      "Slowest Mean: 0.0065975499999999998\n",
      "\n",
      "Speed up: 55.051395341199886\n"
     ]
    }
   ],
   "source": [
    "from tensor import Tensor\n",
    "from random import rand\n",
    "import benchmark\n",
    "from time import sleep\n",
    "from algorithm import vectorize, parallelize\n",
    "\n",
    "alias dtype = DType.float32\n",
    "alias simd_width = simdwidthof[DType.float32]()\n",
    "\n",
    "\n",
    "fn row_mean_naive[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var res = Tensor[dtype](t.dim(0), 1)\n",
    "    for i in range(t.dim(0)):\n",
    "        for j in range(t.dim(1)):\n",
    "            res[i] += t[i, j]\n",
    "        res[i] /= t.dim(1)\n",
    "    return res\n",
    "\n",
    "\n",
    "fn row_mean_fast[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var res = Tensor[dtype](t.dim(0), 1)\n",
    "\n",
    "    @parameter\n",
    "    fn parallel_reduce_rows(idx1: Int) -> None:\n",
    "        @parameter\n",
    "        fn vectorize_reduce_row[simd_width: Int](idx2: Int) -> None:\n",
    "            res[idx1] += t.simd_load[simd_width](idx1 * t.dim(1) + idx2).reduce_add()\n",
    "\n",
    "        vectorize[vectorize_reduce_row, 2 * simd_width](t.dim(1))\n",
    "        res[idx1] /= t.dim(1)\n",
    "\n",
    "    parallelize[parallel_reduce_rows](t.dim(0), t.dim(0))\n",
    "    return res\n",
    "\n",
    "\n",
    "fn main():\n",
    "    var t = rand[dtype](1000, 100000)\n",
    "    var result = Tensor[dtype](t.dim(0), 1)\n",
    "\n",
    "    @parameter\n",
    "    fn bench_mean():\n",
    "        _ = row_mean_naive(t)\n",
    "\n",
    "    @parameter\n",
    "    fn bench_mean_fast():\n",
    "        _ = row_mean_fast(t)\n",
    "\n",
    "    var report = benchmark.run[bench_mean](max_runtime_secs=1)\n",
    "    var report_fast = benchmark.run[bench_mean_fast](max_runtime_secs=1)\n",
    "    report.print()\n",
    "    report_fast.print()\n",
    "    print(\"Speed up:\", report.mean() / report_fast.mean())\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMD enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMD a: [0.5, 0.5, 0.5, 0.5]\n",
      "SIMD b: [2.5, 2.5, 2.5, 2.5]\n",
      "\n",
      "SIMD a.join(b): [0.5, 0.5, 0.5, 0.5, 2.5, 2.5, 2.5, 2.5]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    alias dtype = DType.float32\n",
    "    alias simd_width = simdwidthof[DType.float32]()\n",
    "\n",
    "    var a = SIMD[dtype].splat(0.5)\n",
    "    var b = SIMD[dtype].splat(2.5)\n",
    "\n",
    "    print(\"SIMD a:\", a)\n",
    "    print(\"SIMD b:\", b)\n",
    "    print()\n",
    "    print(\"SIMD a.join(b):\", a.join(b))\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
