{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d0e615-b108-4c15-be4d-ae89b1882562",
   "metadata": {},
   "source": [
    "# Deploying MAX optimized models at scale with Amazon SageMaker and MAX Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45c000-3282-439b-b81d-29e2bf766508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install and update necessary packages\n",
    "!pip install -qU pip awscli boto3 sagemaker transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d7b04-e7ad-43eb-bb16-928fdb3684a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFRobertaForSequenceClassification\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"critical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7267f-c01a-4bf2-9da9-16c5ea5a19cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create boto3 and sagemaker session, get role, bucket name, account number and region\n",
    "sess = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name    = sagemaker_session.default_bucket()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region  = sess.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d54a3-9bd3-4934-848c-338b558ec952",
   "metadata": {},
   "source": [
    "### Step 1: Download a pre-trained Roberta model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba7d5d-d9b9-4e39-b85f-7e14f1298ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_and_save_model(hf_model_name, saved_model_dir):\n",
    "    model = TFRobertaForSequenceClassification.from_pretrained(hf_model_name)\n",
    "    shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "    tf.saved_model.save(model, saved_model_dir+\"/1/saved_model/\")\n",
    "\n",
    "saved_model_dir = \"model-repository/roberta\"\n",
    "hf_model_name = \"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\"\n",
    "download_and_save_model(hf_model_name, saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a850c9d-45a5-4564-933e-8a228d807388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "cat > model-repository/roberta/config.pbtxt <<EOL\n",
    "instance_group {\n",
    "  kind: KIND_CPU\n",
    "}\n",
    "default_model_filename: \"saved_model\"\n",
    "backend: \"max\"\n",
    "EOL\n",
    "\n",
    "tree model-repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3ea42-7635-49fe-8945-bc1ff2043925",
   "metadata": {},
   "source": [
    "### Step 2: Upload model to Amazon S3 so Amazon SageMaker and MAX Serving container has access to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a95a36-6463-4ec6-a7d9-3c2a16fdf807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('model.tar.gz', ignore_errors=True)\n",
    "!tar -C model-repository -czf model.tar.gz roberta\n",
    "\n",
    "model_uri = sagemaker_session.upload_data(path=\"model.tar.gz\", \n",
    "                                          key_prefix=\"max-serving-models/roberta/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576308ae-5f51-4ceb-9d16-45ca6123eb0a",
   "metadata": {},
   "source": [
    "### Step 3: Pull the latest MAX Serving container image and push it to Amazon Elastic Container Registry (Amazon ECR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670217d2-90bd-41cd-9528-c214ef0db6cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = 'sagemaker-max-serving'\n",
    "image_label = 'v1'\n",
    "max_serving_image_uri = \"public.ecr.aws/modular/max-serving-de\"\n",
    "\n",
    "image = f'{account}.dkr.ecr.{region}.amazonaws.com/{repo_name}:{image_label}'\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223258d8-7663-4ba7-8862-6c5f25499021",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws ecr create-repository --repository-name {repo_name}\n",
    "!docker pull {max_serving_image_uri}\n",
    "!docker tag {max_serving_image_uri} {image}\n",
    "!$(aws ecr get-login --no-include-email --region {region})\n",
    "!docker push {image}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64701f2-5d65-4616-8ddc-991df96fc75f",
   "metadata": {},
   "source": [
    "### Step 4: Create an Amazon SageMaker model and deploy to specified instance type. \n",
    "Weâ€™ll use Amazon EC2 c6i.4xlarge, on which MAX Engine can deliver up to 2.6x faster performance vs. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c34ae-d6f8-400c-9126-9b2476978661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.now().strftime(\"%Y-%m-%d-%H-%m-%S\")\n",
    "model_name= f\"MAX-model-roberta-{date}\"\n",
    "\n",
    "max_model = Model(\n",
    "    model_data=model_uri,\n",
    "    name=model_name,\n",
    "    role=role,\n",
    "    image_uri=image,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbc31d-2699-46d4-95af-57a287252d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d-%H-%m-%S\")\n",
    "endpoint_name = f\"MAX-endpoint-roberta-{date}\"\n",
    "\n",
    "predictor = max_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c6i.4xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a3408-063e-4920-a341-ac1c5fe6dbd8",
   "metadata": {},
   "source": [
    "### Step 5: Invoke the endpoint to test the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeabea8-dd06-4940-a7b0-65579800307c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(hf_model_name)\n",
    "client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922c371-7b7d-45ee-acfc-37bfe1107140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"MAX Serving and Amazon SageMaker are a match made in heaven\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name)\n",
    "inputs = tokenizer(text, \n",
    "                   return_tensors=\"np\", \n",
    "                   return_token_type_ids=True)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"input_ids\", \n",
    "         \"shape\": inputs[\"input_ids\"].shape, \n",
    "         \"datatype\": \"INT32\", \"data\": inputs[\"input_ids\"].tolist()},\n",
    "        {\"name\": \"attention_mask\", \n",
    "         \"shape\": inputs[\"attention_mask\"].shape, \n",
    "         \"datatype\": \"INT32\", \n",
    "         \"data\": inputs[\"attention_mask\"].tolist()},\n",
    "        {\"name\": \"token_type_ids\", \n",
    "         \"shape\": inputs[\"token_type_ids\"].shape, \n",
    "         \"datatype\": \"INT32\", \n",
    "         \"data\": inputs[\"token_type_ids\"].tolist()},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028dbef-19a0-49fc-8242-b53d8f570849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "http_response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType=\"application/octet-stream\", Body=json.dumps(payload)\n",
    ")\n",
    "response = json.loads(http_response[\"Body\"].read().decode(\"utf8\"))\n",
    "outputs = response[\"outputs\"]\n",
    "predicted_class_id = np.argmax(outputs[0]['data'],axis=-1)\n",
    "classification = model.config.id2label[predicted_class_id]\n",
    "print(f\"The sentiment of the input statement is: {classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43cc62-3e25-4f4f-817c-f44571906066",
   "metadata": {},
   "source": [
    "### Step 6: Clean up AWS resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4438c9-8dd3-4b31-b1ec-7b46edd15925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm = sess.client('sagemaker')\n",
    "endpoint_config_name = sm.describe_endpoint(EndpointName=endpoint_name)['EndpointConfigName']\n",
    "model_name = sm.describe_endpoint_config(EndpointConfigName=endpoint_config_name)['ProductionVariants'][0]['ModelName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e1448-ab44-493f-b7c4-12ba38d5f76b",
   "metadata": {},
   "source": [
    "#### Delete endpoint and clean up model and endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55012c-8609-4bae-b0dd-e2039abf8bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbeeac-95da-4fbc-9854-8fecdb00bfcc",
   "metadata": {},
   "source": [
    "#### Delete model artifacts in Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1dc3c-0d7f-4f38-a43a-758a8aea3599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket.objects.filter(Prefix=\"max-serving-models/roberta/\").all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c518b4-b8cb-46ab-b0e2-5516c7c3962e",
   "metadata": {},
   "source": [
    "#### Delete Amazon ECR registry and all the images we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245b193-0cb4-4bc0-a1f4-f934d3a57cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecr = boto3.client('ecr')\n",
    "ecr.delete_repository(registryId=account,\n",
    "                      repositoryName=repo_name,\n",
    "                      force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
